"""
–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ HydraAI API
"""
import asyncio
import os
from dotenv import load_dotenv

from agent import ChatOpenAI
from agent.llm.messages import UserMessage

load_dotenv()

async def test_hydra_api():
    """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ HydraAI API"""
    
    openai_key = os.getenv('OPENAI_API_KEY')
    base_url = os.getenv('OPENAI_BASE_URL') or os.getenv('OPENAI_API_URL')
    
    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω OPENAI_API_URL —Å –ø–æ–ª–Ω—ã–º –ø—É—Ç—ë–º /chat/completions, —É–±–∏—Ä–∞–µ–º –µ–≥–æ
    if base_url and '/chat/completions' in base_url:
        base_url = base_url.replace('/chat/completions', '')
    
    print(f"üîë API Key: {openai_key[:20]}...")
    print(f"üåê Base URL: {base_url}")
    
    if not openai_key:
        print("‚ùå OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")
        return
    
    # –°–æ–∑–¥–∞—ë–º –∫–ª–∏–µ–Ω—Ç OpenAI —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º base_url
    llm = ChatOpenAI(
        model='gpt-4o-mini',
        api_key=openai_key,
        base_url=base_url
    )
    
    print("\nüì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å...")
    
    try:
        response = await llm.ainvoke([
            UserMessage(content="–ü—Ä–∏–≤–µ—Ç! –û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º: –∫–∞–∫ –¥–µ–ª–∞?")
        ])
        
        print(f"\n‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç:")
        print(f"üìù {response.completion}")
        if response.usage:
            print(f"üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {response.usage.total_tokens} (prompt: {response.usage.prompt_tokens}, completion: {response.usage.completion_tokens})")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ:")
        print(f"   {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    asyncio.run(test_hydra_api())

